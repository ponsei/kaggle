# Titanic TensorFlow Decision Forests ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ - æ‰‹é †å¯è¦–åŒ–

## ğŸ“Š å…¨ä½“ãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ

```mermaid
graph TD
    A[é–‹å§‹] --> B[1. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ]
    B --> C[2. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿]
    C --> D[3. ãƒ‡ãƒ¼ã‚¿æ¢ç´¢ EDA]
    D --> E[4. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†]
    E --> F[5. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°]
    F --> G[6. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¤‰æ›]
    G --> H[7. ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰]
    H --> I[8. ãƒ¢ãƒ‡ãƒ«è¨“ç·´]
    I --> J[9. ãƒ¢ãƒ‡ãƒ«è©•ä¾¡]
    J --> K[10. äºˆæ¸¬ç”Ÿæˆ]
    K --> L[11. ãƒ¢ãƒ‡ãƒ«å¯è¦–åŒ–]
    L --> M[çµ‚äº†]
    
    style A fill:#e1f5ff
    style M fill:#e1f5ff
    style H fill:#fff4e1
    style I fill:#fff4e1
    style J fill:#fff4e1
```

## ğŸ” è©³ç´°æ‰‹é †

### ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

```python
import tensorflow as tf
import tensorflow_decision_forests as tfdf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
```

**ç›®çš„**: å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’æº–å‚™

---

### ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿

```python
train_df = pd.read_csv('/kaggle/input/titanic/train.csv')
test_df = pd.read_csv('/kaggle/input/titanic/test.csv')
```

**ãƒ‡ãƒ¼ã‚¿æ§‹é€ **:
- `train.csv`: 891è¡Œ Ã— 12åˆ—ï¼ˆSurvivedå«ã‚€ï¼‰
- `test.csv`: 418è¡Œ Ã— 11åˆ—ï¼ˆSurvivedãªã—ï¼‰

---

### ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ‡ãƒ¼ã‚¿æ¢ç´¢ï¼ˆEDAï¼‰

```mermaid
graph LR
    A[ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿] --> B[åŸºæœ¬æƒ…å ±ç¢ºèª]
    B --> C[æ¬ æå€¤ç¢ºèª]
    C --> D[çµ±è¨ˆæƒ…å ±ç¢ºèª]
    D --> E[å¯è¦–åŒ–]
    
    B --> B1[.info]
    B --> B2[.head]
    B --> B3[.shape]
    
    C --> C1[.isnull.sum]
    C --> C2[æ¬ æç‡è¨ˆç®—]
    
    D --> D1[.describe]
    D --> D2[.value_counts]
    
    E --> E1[ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ]
    E --> E2[ç›¸é–¢è¡Œåˆ—]
    E --> E3[ç®±ã²ã’å›³]
```

**å®Ÿè¡Œã‚³ãƒ¼ãƒ‰ä¾‹**:
```python
# åŸºæœ¬æƒ…å ±
train_df.info()
train_df.describe()

# æ¬ æå€¤ç¢ºèª
train_df.isnull().sum()

# å¯è¦–åŒ–
sns.histplot(train_df['Age'].dropna(), bins=30)
plt.title('Age Distribution')
plt.show()
```

---

### ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†

```mermaid
graph TD
    A[ç”Ÿãƒ‡ãƒ¼ã‚¿] --> B[æ¬ æå€¤å‡¦ç†]
    B --> C[ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°å‡¦ç†]
    C --> D[æ•°å€¤å¤‰æ•°å‡¦ç†]
    D --> E[å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿]
    
    B --> B1[Age: ä¸­å¤®å€¤ã§è£œå®Œ]
    B --> B2[Embarked: æœ€é »å€¤ã§è£œå®Œ]
    B --> B3[Cabin: å‰Šé™¤ or æ–°ç‰¹å¾´é‡]
    
    C --> C1[Sex: 0/1å¤‰æ›]
    C --> C2[Embarked: ãƒ€ãƒŸãƒ¼å¤‰æ•°]
    
    D --> D1[Fare: æ­£è¦åŒ– or ãã®ã¾ã¾]
    D --> D2[Pclass: ãã®ã¾ã¾ or ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°]
```

**å®Ÿè¡Œã‚³ãƒ¼ãƒ‰ä¾‹**:
```python
# æ¬ æå€¤è£œå®Œ
train_df['Age'].fillna(train_df['Age'].median(), inplace=True)
train_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace=True)

# ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
train_df['Sex'] = train_df['Sex'].map({'male': 0, 'female': 1})
train_df = pd.get_dummies(train_df, columns=['Embarked'], prefix='Emb')
```

---

### ã‚¹ãƒ†ãƒƒãƒ—5: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°

```mermaid
graph TD
    A[å…ƒã®ç‰¹å¾´é‡] --> B[æ–°ç‰¹å¾´é‡ä½œæˆ]
    B --> C[ç‰¹å¾´é‡é¸æŠ]
    C --> D[æœ€çµ‚ç‰¹å¾´é‡ã‚»ãƒƒãƒˆ]
    
    B --> B1[Title: Nameã‹ã‚‰æŠ½å‡º]
    B --> B2[FamilySize: SibSp + Parch + 1]
    B --> B3[IsAlone: FamilySize == 1]
    B --> B4[AgeGroup: Ageã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–]
    B --> B5[FarePerPerson: Fare / FamilySize]
    
    C --> C1[ä¸è¦ãªåˆ—å‰Šé™¤]
    C --> C2[ç›¸é–¢ã®é«˜ã„ç‰¹å¾´é‡å‰Šé™¤]
```

**å®Ÿè¡Œã‚³ãƒ¼ãƒ‰ä¾‹**:
```python
# TitleæŠ½å‡º
train_df['Title'] = train_df['Name'].str.extract(' ([A-Za-z]+)\.', expand=False)
title_mapping = {"Mr": 1, "Miss": 2, "Mrs": 3, "Master": 4, "Rare": 5}
train_df['Title'] = train_df['Title'].map(title_mapping)

# FamilySize
train_df['FamilySize'] = train_df['SibSp'] + train_df['Parch'] + 1
train_df['IsAlone'] = (train_df['FamilySize'] == 1).astype(int)
```

---

### ã‚¹ãƒ†ãƒƒãƒ—6: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¤‰æ›

```mermaid
graph LR
    A[Pandas DataFrame] --> B[pd_dataframe_to_tf_dataset]
    B --> C[TensorFlow Dataset]
    
    A --> A1[train_df]
    A --> A2[test_df]
    
    C --> C1[train_ds]
    C --> C2[test_ds]
```

**å®Ÿè¡Œã‚³ãƒ¼ãƒ‰**:
```python
# ãƒ©ãƒ™ãƒ«åˆ—ã‚’æŒ‡å®šã—ã¦å¤‰æ›
train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(
    train_df.drop('Survived', axis=1), 
    label='Survived'
)

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ©ãƒ™ãƒ«ãªã—ï¼‰
test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(
    test_df
)
```

---

### ã‚¹ãƒ†ãƒƒãƒ—7: ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰

```mermaid
graph TD
    A[ãƒ¢ãƒ‡ãƒ«é¸æŠ] --> B[ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š]
    B --> C[ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ]
    C --> D[ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«]
    
    A --> A1[RandomForestModel]
    A --> A2[GradientBoostedTreesModel]
    A --> A3[CARTModel]
    
    B --> B1[num_trees: 100]
    B --> B2[max_depth: 16]
    B --> B3[min_examples: 5]
```

**å®Ÿè¡Œã‚³ãƒ¼ãƒ‰**:
```python
# ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«
model = tfdf.keras.RandomForestModel(
    num_trees=100,
    max_depth=16,
    min_examples=5,
    task=tfdf.keras.Task.CLASSIFICATION
)

# ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ï¼ˆãƒ¡ãƒˆãƒªã‚¯ã‚¹æŒ‡å®šï¼‰
model.compile(metrics=['accuracy'])
```

---

### ã‚¹ãƒ†ãƒƒãƒ—8: ãƒ¢ãƒ‡ãƒ«è¨“ç·´

```mermaid
graph LR
    A[è¨“ç·´ãƒ‡ãƒ¼ã‚¿] --> B[model.fit]
    B --> C[è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«]
    
    B --> B1[ã‚¨ãƒãƒƒã‚¯æ•°]
    B --> B2[ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³åˆ†å‰²]
    B --> B3[ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯]
```

**å®Ÿè¡Œã‚³ãƒ¼ãƒ‰**:
```python
# ãƒ¢ãƒ‡ãƒ«è¨“ç·´
model.fit(train_ds)

# ã¾ãŸã¯ã€ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³åˆ†å‰²ã‚ã‚Š
model.fit(
    train_ds,
    validation_split=0.2,
    verbose=1
)
```

---

### ã‚¹ãƒ†ãƒƒãƒ—9: ãƒ¢ãƒ‡ãƒ«è©•ä¾¡

```mermaid
graph TD
    A[è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«] --> B[ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿è©•ä¾¡]
    B --> C[ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—]
    C --> D[çµæœè¡¨ç¤º]
    
    C --> C1[Accuracy]
    C --> C2[Precision]
    C --> C3[Recall]
    C --> C4[F1-Score]
```

**å®Ÿè¡Œã‚³ãƒ¼ãƒ‰**:
```python
# è©•ä¾¡
evaluation = model.evaluate(test_ds, return_dict=True)
print(f"Test Accuracy: {evaluation['accuracy']:.4f}")

# äºˆæ¸¬
predictions = model.predict(test_ds)
predictions_binary = (predictions > 0.5).astype(int)
```

---

### ã‚¹ãƒ†ãƒƒãƒ—10: äºˆæ¸¬ç”Ÿæˆã¨æå‡º

```mermaid
graph LR
    A[ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿] --> B[äºˆæ¸¬å®Ÿè¡Œ]
    B --> C[ãƒã‚¤ãƒŠãƒªå¤‰æ›]
    C --> D[æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ]
    D --> E[CSVå‡ºåŠ›]
```

**å®Ÿè¡Œã‚³ãƒ¼ãƒ‰**:
```python
# äºˆæ¸¬
predictions = model.predict(test_ds)
predictions_binary = (predictions > 0.5).astype(int).flatten()

# æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
submission = pd.DataFrame({
    'PassengerId': test_df['PassengerId'],
    'Survived': predictions_binary
})

submission.to_csv('submission.csv', index=False)
```

---

### ã‚¹ãƒ†ãƒƒãƒ—11: ãƒ¢ãƒ‡ãƒ«å¯è¦–åŒ–

```mermaid
graph TD
    A[è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«] --> B[æ±ºå®šæœ¨å¯è¦–åŒ–]
    A --> C[ç‰¹å¾´é‡é‡è¦åº¦]
    A --> D[ãƒ¢ãƒ‡ãƒ«çµ±è¨ˆ]
    
    B --> B1[ç‰¹å®šã®æœ¨ã‚’è¡¨ç¤º]
    B --> B2[æ·±ã•åˆ¶é™]
    
    C --> C1[é‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°]
    C --> C2[é‡è¦åº¦ãƒ—ãƒ­ãƒƒãƒˆ]
```

**å®Ÿè¡Œã‚³ãƒ¼ãƒ‰**:
```python
# æ±ºå®šæœ¨ã®å¯è¦–åŒ–
tfdf.model_plotter.plot_model_in_colab(model, tree_idx=0, max_depth=3)

# ç‰¹å¾´é‡é‡è¦åº¦
importances = model.make_inspector().variable_importances()
print(importances)

# çµ±è¨ˆæƒ…å ±
inspector = model.make_inspector()
print(inspector.num_trees())
print(inspector.evaluation())
```

---

## ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼å…¨ä½“å›³

```mermaid
graph TB
    subgraph "ãƒ‡ãƒ¼ã‚¿æº–å‚™ãƒ•ã‚§ãƒ¼ã‚º"
        A1[CSVãƒ•ã‚¡ã‚¤ãƒ«] --> A2[Pandas DataFrame]
        A2 --> A3[EDAãƒ»æ¢ç´¢]
        A3 --> A4[å‰å‡¦ç†]
        A4 --> A5[ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°]
    end
    
    subgraph "ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ãƒ•ã‚§ãƒ¼ã‚º"
        A5 --> B1[TF Datasetå¤‰æ›]
        B1 --> B2[ãƒ¢ãƒ‡ãƒ«å®šç¾©]
        B2 --> B3[ãƒ¢ãƒ‡ãƒ«è¨“ç·´]
    end
    
    subgraph "è©•ä¾¡ãƒ»äºˆæ¸¬ãƒ•ã‚§ãƒ¼ã‚º"
        B3 --> C1[ãƒ¢ãƒ‡ãƒ«è©•ä¾¡]
        B3 --> C2[äºˆæ¸¬ç”Ÿæˆ]
        C2 --> C3[æå‡ºãƒ•ã‚¡ã‚¤ãƒ«]
        B3 --> C4[ãƒ¢ãƒ‡ãƒ«å¯è¦–åŒ–]
    end
    
    style A1 fill:#e1f5ff
    style B2 fill:#fff4e1
    style B3 fill:#fff4e1
    style C3 fill:#e8f5e9
```

## ğŸ¯ é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

1. **TF-DFã®åˆ©ç‚¹**: ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã‚’è‡ªå‹•å‡¦ç†ã€å‰å‡¦ç†ãŒç°¡å˜
2. **ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°**: Titleã€FamilySizeãªã©ãŒé‡è¦
3. **ãƒ¢ãƒ‡ãƒ«é¸æŠ**: RandomForestModelãŒä¸€èˆ¬çš„ã«è‰¯ã„æ€§èƒ½
4. **å¯è¦–åŒ–**: æ±ºå®šæœ¨ã®æ§‹é€ ã‚’ç¢ºèªã—ã¦è§£é‡ˆæ€§ã‚’ç¢ºä¿

## ğŸ“ å…¸å‹çš„ãªã‚³ãƒ¼ãƒ‰æ§‹é€ 

```python
# ============================================
# 1. ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# ============================================
import tensorflow as tf
import tensorflow_decision_forests as tfdf
import pandas as pd

# ============================================
# 2. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# ============================================
train_df = pd.read_csv('/kaggle/input/titanic/train.csv')
test_df = pd.read_csv('/kaggle/input/titanic/test.csv')

# ============================================
# 3. å‰å‡¦ç†
# ============================================
# æ¬ æå€¤å‡¦ç†ã€ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãªã©

# ============================================
# 4. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¤‰æ›
# ============================================
train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(
    train_df.drop('Survived', axis=1), 
    label='Survived'
)

# ============================================
# 5. ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ãƒ»è¨“ç·´
# ============================================
model = tfdf.keras.RandomForestModel()
model.compile(metrics=['accuracy'])
model.fit(train_ds)

# ============================================
# 6. äºˆæ¸¬ãƒ»æå‡º
# ============================================
test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_df)
predictions = model.predict(test_ds)
# æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ...
```

